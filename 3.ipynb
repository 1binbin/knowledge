{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **花卉类型识别**\n",
    "\n",
    "1. 解压数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 解压数据集，只需要第一次运行时解压，第二次无需再解压\r\n",
    "!wget https://ascend-professional-construction-dataset.obs.myhuaweicloud.com/deep-learning/flower_photos.zip \r\n",
    "!unzip flower_photos.zip "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "2. 导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#easydict模块用于以属性的方式访问字典的值\r\n",
    "from easydict import EasyDict as edict\r\n",
    "#glob模块主要用于查找符合特定规则的文件路径名，类似使用windows下的文件搜索\r\n",
    "import glob\r\n",
    "#os模块主要用于处理文件和目录\r\n",
    "import os\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "import mindspore\r\n",
    "#导入mindspore框架数据集\r\n",
    "import mindspore.dataset as ds\r\n",
    "#vision.c_transforms模块是处理图像增强的高性能模块，用于数据增强图像数据改进训练模型。\r\n",
    "import mindspore.dataset.vision.c_transforms as CV\r\n",
    "#c_transforms模块提供常用操作，包括OneHotOp和TypeCast\r\n",
    "import mindspore.dataset.transforms.c_transforms as C\r\n",
    "from mindspore.common import dtype as mstype\r\n",
    "from mindspore import context\r\n",
    "#导入模块用于初始化截断正态分布\r\n",
    "from mindspore.common.initializer import TruncatedNormal\r\n",
    "from mindspore import nn\r\n",
    "from mindspore.train import Model\r\n",
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig, LossMonitor, TimeMonitor\r\n",
    "from mindspore.train.serialization import load_checkpoint, load_param_into_net\r\n",
    "from mindspore import Tensor\r\n",
    "# 设置MindSpore的执行模式和设备\r\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"Ascend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "3. 定义变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfg = edict({\r\n",
    "    'data_path': 'flower_photos',\r\n",
    "    'data_size':3670,\r\n",
    "    'image_width': 100,  # 图片宽度\r\n",
    "    'image_height': 100,  # 图片高度\r\n",
    "    'batch_size': 32,\r\n",
    "    'channel': 3,  # 图片通道数\r\n",
    "    'num_class':5,  # 分类类别\r\n",
    "    'weight_decay': 0.01,\r\n",
    "    'lr':0.0001,  # 学习率\r\n",
    "    'dropout_ratio': 0.5,\r\n",
    "    'epoch_size': 400,  # 训练次数\r\n",
    "    'sigma':0.01,\r\n",
    "    'save_checkpoint_steps': 1,  # 多少步保存一次模型\r\n",
    "    'keep_checkpoint_max': 1,  # 最多保存多少个模型\r\n",
    "    'output_directory': './',  # 保存模型路径\r\n",
    "    'output_prefix': \"checkpoint_classification\"  # 保存模型文件名字\r\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "4. 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#从目录中读取图像的源数据集。\r\n",
    "de_dataset = ds.ImageFolderDataset(cfg.data_path,\r\n",
    "                                   class_indexing={'daisy':0,'dandelion':1,'roses':2,'sunflowers':3,'tulips':4})\r\n",
    "#解码前将输入图像裁剪成任意大小和宽高比。\r\n",
    "transform_img = CV.RandomCropDecodeResize([cfg.image_width,cfg.image_height], scale=(0.08, 1.0), ratio=(0.75, 1.333))  #改变尺寸\r\n",
    "#转换输入图像；形状（H, W, C）为形状（C, H, W）。\r\n",
    "hwc2chw_op = CV.HWC2CHW()\r\n",
    "#转换为给定MindSpore数据类型的Tensor操作。\r\n",
    "type_cast_op = C.TypeCast(mstype.float32)\r\n",
    "#将操作中的每个操作应用到此数据集。\r\n",
    "de_dataset = de_dataset.map(input_columns=\"image\", num_parallel_workers=8, operations=transform_img)\r\n",
    "de_dataset = de_dataset.map(input_columns=\"image\", operations=hwc2chw_op, num_parallel_workers=8)\r\n",
    "de_dataset = de_dataset.map(input_columns=\"image\", operations=type_cast_op, num_parallel_workers=8)\r\n",
    "de_dataset = de_dataset.shuffle(buffer_size=cfg.data_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "5. 划分数据集和训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#划分训练集测试集\r\n",
    "(de_train,de_test)=de_dataset.split([0.8,0.2])\r\n",
    "#设置每个批处理的行数\r\n",
    "#drop_remainder确定是否删除最后一个可能不完整的批（default=False）。\r\n",
    "#如果为True，并且如果可用于生成最后一个批的batch_size行小于batch_size行，则这些行将被删除，并且不会传播到子节点。\r\n",
    "de_train=de_train.batch(cfg.batch_size, drop_remainder=True)\r\n",
    "#重复此数据集计数次数。\r\n",
    "de_test=de_test.batch(cfg.batch_size, drop_remainder=True)\r\n",
    "print('训练数据集数量：',de_train.get_dataset_size()*cfg.batch_size)#get_dataset_size()获取批处理的大小。\r\n",
    "print('测试数据集数量：',de_test.get_dataset_size()*cfg.batch_size)\r\n",
    "\r\n",
    "data_next=de_dataset.create_dict_iterator(output_numpy=True).__next__()\r\n",
    "print('通道数/图像长/宽：', data_next['image'].shape)\r\n",
    "print('一张图像的标签样式：', data_next['label'])  # 一共5类，用0-4的数字表达类别。\r\n",
    "\r\n",
    "plt.figure()\r\n",
    "plt.imshow(data_next['image'][0,...])\r\n",
    "plt.colorbar()\r\n",
    "plt.grid(False)\r\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "输出：\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/73e25fde8c4a488d867d2be7ae9318ee2ee07d8de6e844b0a0838c71d344589c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "6. 构建CNN图像识别模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义CNN图像识别网络\r\n",
    "class Identification_Net(nn.Cell):\r\n",
    "    def __init__(self, num_class=5,channel=3,dropout_ratio=0.5,trun_sigma=0.01):  # 一共分五类，图片通道数是3\r\n",
    "        super(Identification_Net, self).__init__()\r\n",
    "        self.num_class = num_class\r\n",
    "        self.channel = channel\r\n",
    "        self.dropout_ratio = dropout_ratio\r\n",
    "        #设置卷积层\r\n",
    "        self.conv1 = nn.Conv2d(self.channel, 32,\r\n",
    "                               kernel_size=5, stride=1, padding=0,\r\n",
    "                               has_bias=True, pad_mode=\"same\",\r\n",
    "                               weight_init=TruncatedNormal(sigma=trun_sigma),bias_init='zeros')\r\n",
    "        #设置ReLU激活函数\r\n",
    "        self.relu = nn.ReLU()\r\n",
    "        #设置最大池化层\r\n",
    "        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2,pad_mode=\"valid\")\r\n",
    "        self.conv2 = nn.Conv2d(32, 64,\r\n",
    "                               kernel_size=5, stride=1, padding=0,\r\n",
    "                               has_bias=True, pad_mode=\"same\",\r\n",
    "                               weight_init=TruncatedNormal(sigma=trun_sigma),bias_init='zeros')\r\n",
    "        self.conv3 = nn.Conv2d(64, 128,\r\n",
    "                               kernel_size=3, stride=1, padding=0,\r\n",
    "                               has_bias=True, pad_mode=\"same\",\r\n",
    "                               weight_init=TruncatedNormal(sigma=trun_sigma),bias_init='zeros')\r\n",
    "        self.conv4 = nn.Conv2d(128, 128,\r\n",
    "                               kernel_size=3, stride=1, padding=0,\r\n",
    "                               has_bias=True, pad_mode=\"same\",\r\n",
    "                               weight_init=TruncatedNormal(sigma=trun_sigma), bias_init='zeros')\r\n",
    "        self.flatten = nn.Flatten()\r\n",
    "        self.fc1 = nn.Dense(6*6*128, 1024,weight_init =TruncatedNormal(sigma=trun_sigma),bias_init = 0.1)\r\n",
    "        self.dropout = nn.Dropout(self.dropout_ratio)\r\n",
    "        self.fc2 = nn.Dense(1024, 512, weight_init=TruncatedNormal(sigma=trun_sigma), bias_init=0.1)\r\n",
    "        self.fc3 = nn.Dense(512, self.num_class, weight_init=TruncatedNormal(sigma=trun_sigma), bias_init=0.1)\r\n",
    "    #构建模型\r\n",
    "    def construct(self, x):\r\n",
    "        x = self.conv1(x)\r\n",
    "        #print(x.shape)\r\n",
    "        x = self.relu(x)\r\n",
    "        x = self.max_pool2d(x)\r\n",
    "        x = self.conv2(x)\r\n",
    "        x = self.relu(x)\r\n",
    "        x = self.max_pool2d(x)\r\n",
    "        x = self.conv3(x)\r\n",
    "        x = self.max_pool2d(x)\r\n",
    "        x = self.conv4(x)\r\n",
    "        x = self.max_pool2d(x)\r\n",
    "        x = self.flatten(x)\r\n",
    "        x = self.fc1(x)\r\n",
    "        x = self.relu(x)\r\n",
    "        #print(x.shape)\r\n",
    "        x = self.dropout(x)\r\n",
    "        x = self.fc2(x)\r\n",
    "        x = self.relu(x)\r\n",
    "        x = self.dropout(x)\r\n",
    "        x = self.fc3(x)\r\n",
    "        return x\r\n",
    "net=Identification_Net(num_class=cfg.num_class, channel=cfg.channel, dropout_ratio=cfg.dropout_ratio)\r\n",
    "#计算softmax交叉熵。\r\n",
    "net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction=\"mean\")\r\n",
    "#opt\r\n",
    "fc_weight_params = list(filter(lambda x: 'fc' in x.name and 'weight' in x.name, net.trainable_params()))\r\n",
    "other_params=list(filter(lambda x: 'fc' not in x.name or 'weight' not in x.name, net.trainable_params()))\r\n",
    "group_params = [{'params': fc_weight_params, 'weight_decay': cfg.weight_decay},\r\n",
    "                {'params': other_params},\r\n",
    "                {'order_params': net.trainable_params()}]\r\n",
    "#设置Adam优化器\r\n",
    "net_opt = nn.Adam(group_params, learning_rate=cfg.lr, weight_decay=0.0)\r\n",
    "#net_opt = nn.Adam(params=net.trainable_params(), learning_rate=cfg.lr, weight_decay=0.1)\r\n",
    "\r\n",
    "model = Model(net, loss_fn=net_loss, optimizer=net_opt, metrics={\"acc\"})\r\n",
    "loss_cb = LossMonitor(per_print_times=de_train.get_dataset_size()*10)\r\n",
    "config_ck = CheckpointConfig(save_checkpoint_steps=cfg.save_checkpoint_steps,\r\n",
    "                             keep_checkpoint_max=cfg.keep_checkpoint_max)\r\n",
    "ckpoint_cb = ModelCheckpoint(prefix=cfg.output_prefix, directory=cfg.output_directory, config=config_ck)\r\n",
    "print(\"============== Starting Training ==============\")\r\n",
    "model.train(cfg.epoch_size, de_train, callbacks=[loss_cb, ckpoint_cb], dataset_sink_mode=True)\r\n",
    "\r\n",
    "# 使用测试集评估模型，打印总体准确率\r\n",
    "metric = model.eval(de_test)\r\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "输出：\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/c04ea591c6a14918b8492aa0c9fe9e532142e842be76486a97a974f36158bcce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "7. 图像分类模型验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#加载模型\r\n",
    "import os\r\n",
    "CKPT = os.path.join(cfg.output_directory,cfg.output_prefix+'-'+str(cfg.epoch_size)+'_'+str(de_train.get_dataset_size())+'.ckpt')\r\n",
    "net = Identification_Net(num_class=cfg.num_class, channel=cfg.channel, dropout_ratio=cfg.dropout_ratio)\r\n",
    "load_checkpoint(CKPT, net=net)\r\n",
    "model = Model(net) \r\n",
    "# 预测\r\n",
    "class_names = {0:'daisy',1:'dandelion',2:'roses',3:'sunflowers',4:'tulips'}\r\n",
    "test_ = de_test.create_dict_iterator().__next__()\r\n",
    "test = Tensor(test_['image'], mindspore.float32)\r\n",
    "predictions = model.predict(test)\r\n",
    "predictions = predictions.asnumpy()\r\n",
    "true_label = test_['label'].asnumpy()\r\n",
    "\r\n",
    "#显示预测结果\r\n",
    "for i in range(10):\r\n",
    "    p_np = predictions[i, :]\r\n",
    "    pre_label = np.argmax(p_np)\r\n",
    "    print('第' + str(i) + '个sample预测结果：', class_names[pre_label], '   真实结果：', class_names[true_label[i]]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "输出：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/b4eed518fcbd4a55b6d6f90a751bccec3eb30561af5c41e3b1117e072dd970e6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
