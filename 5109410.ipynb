{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 把宝石25或者87，在华为平台上完成实验\n",
    "\n",
    "(1)请用Markdown写出每一步骤。\n",
    "\n",
    "(2)写出学习心得。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#easydict模块用于以属性的方式访问字典的值\r\n",
    "from easydict import EasyDict as edict\r\n",
    "#os模块主要用于处理文件和目录\r\n",
    "import os\r\n",
    "import zipfile\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "import mindspore\r\n",
    "#导入mindspore框架数据集\r\n",
    "import mindspore.dataset as ds\r\n",
    "#vision.c_transforms模块是处理图像增强的高性能模块，用于数据增强图像数据改进训练模型。\r\n",
    "from mindspore.dataset.vision import c_transforms as vision\r\n",
    "from mindspore import context\r\n",
    "import mindspore.nn as nn\r\n",
    "from mindspore.train import Model\r\n",
    "from mindspore.nn.optim.momentum import Momentum\r\n",
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig, LossMonitor\r\n",
    "from mindspore import Tensor\r\n",
    "from mindspore.train.serialization import export\r\n",
    "from mindspore.train.loss_scale_manager import FixedLossScaleManager\r\n",
    "from mindspore.train.serialization import load_checkpoint, load_param_into_net\r\n",
    "import mindspore.ops as ops\r\n",
    "\r\n",
    "# 设置MindSpore的执行模式和设备\r\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"Ascend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 解压数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unzip_data(src_path,target_path):\r\n",
    "    '''\r\n",
    "    解压原始数据集，将src_path路径下的zip包解压至data/dataset目录下\r\n",
    "    '''\r\n",
    "    if(not os.path.isdir(target_path)):\r\n",
    "        z = zipfile.ZipFile(src_path, 'r')\r\n",
    "        z.extractall(path=target_path)\r\n",
    "        z.close()\r\n",
    "    else:\r\n",
    "        print(\"文件已解压\")\r\n",
    "unzip_data(\"./archive_train.zip\", \"./trainset\")\r\n",
    "unzip_data(\"./archive_test.zip\", \"./testset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/8014599db7594f0182a9ca1fe900662ff56cd49dbfc44ad0a8a5e96e117a78d4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 定义变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfg = edict({\r\n",
    "    'data_path': './trainset',   #训练数据集，如果是zip文件需要解压\r\n",
    "    'test_path':'./testset',     #测试数据集，如果是zip文件需要解压\r\n",
    "    'data_size': 800,\r\n",
    "    'HEIGHT': 224,  # 图片高度\r\n",
    "    'WIDTH': 224,  # 图片宽度\r\n",
    "    '_R_MEAN': 123.68,\r\n",
    "    '_G_MEAN': 116.78,\r\n",
    "    '_B_MEAN': 103.94,\r\n",
    "    '_R_STD': 1,\r\n",
    "    '_G_STD': 1,\r\n",
    "    '_B_STD':1,\r\n",
    "    '_RESIZE_SIDE_MIN': 256,\r\n",
    "    '_RESIZE_SIDE_MAX': 512,\r\n",
    "    \r\n",
    "    'batch_size': 32,\r\n",
    "    'num_class': 25,     # 分类类别\r\n",
    "    'epoch_size': 100,  # 训练次数\r\n",
    "    'loss_scale_num':1024,\r\n",
    "    \r\n",
    "    'prefix': 'resnet-ai',\r\n",
    "    'directory': './model_resnet',\r\n",
    "    'save_checkpoint_steps': 10,\r\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_data(path,config,usage=\"train\"):\r\n",
    "    #从目录中读取图像的源数据集。\r\n",
    "    dataset = ds.ImageFolderDataset(path,\r\n",
    "                                   class_indexing={'Alexandrite':0,'Almandine':1,'Benitoite':2,'Beryl Golden':3,'Carnelian':4,'Cats Eye':5,'Danburite':6,'Diamond':7,'Emerald':8,'Fluorite':9,'Garnet Red':10,'Hessonite':11,'Iolite':12,'Jade':13,'Kunzite':14,'Labradorite':15,'Malachite':16,'Onyx Black':17,'Pearl':18,'Quartz Beer':19,'Rhodochrosite':20,'Sapphire Blue':21,' Tanzanite ':22,' Variscite ':23,' Zircon ':24})\r\n",
    "    # define map operations\r\n",
    "    decode_op = vision.Decode()\r\n",
    "    normalize_op = vision.Normalize(mean=[cfg._R_MEAN, cfg._G_MEAN, cfg._B_MEAN], std=[cfg._R_STD, cfg._G_STD, cfg._B_STD])\r\n",
    "    resize_op = vision.Resize(cfg._RESIZE_SIDE_MIN)\r\n",
    "    center_crop_op = vision.CenterCrop((cfg.HEIGHT, cfg.WIDTH))\r\n",
    "    horizontal_flip_op = vision.RandomHorizontalFlip()\r\n",
    "    channelswap_op = vision.HWC2CHW()\r\n",
    "    random_crop_decode_resize_op = vision.RandomCropDecodeResize((cfg.HEIGHT, cfg.WIDTH), (0.5, 1.0), (1.0, 1.0), max_attempts=100)\r\n",
    "\r\n",
    "    if usage == 'train':\r\n",
    "        dataset = dataset.map(input_columns=\"image\", operations=random_crop_decode_resize_op)\r\n",
    "        dataset = dataset.map(input_columns=\"image\", operations=horizontal_flip_op)\r\n",
    "    else:\r\n",
    "        dataset = dataset.map(input_columns=\"image\", operations=decode_op)\r\n",
    "        dataset = dataset.map(input_columns=\"image\", operations=resize_op)\r\n",
    "        dataset = dataset.map(input_columns=\"image\", operations=center_crop_op)\r\n",
    "\r\n",
    "    dataset = dataset.map(input_columns=\"image\", operations=normalize_op)\r\n",
    "    dataset = dataset.map(input_columns=\"image\", operations=channelswap_op)\r\n",
    "\r\n",
    "    if usage == 'train':\r\n",
    "        dataset = dataset.shuffle(buffer_size=10000)  # 10000 as in imageNet train script\r\n",
    "        dataset = dataset.batch(cfg.batch_size, drop_remainder=True)\r\n",
    "    else:\r\n",
    "        dataset = dataset.batch(1, drop_remainder=True)\r\n",
    "    dataset = dataset.repeat(1)\r\n",
    "    dataset.map_model = 4\r\n",
    "\r\n",
    "    return dataset\r\n",
    "   \r\n",
    "de_train = read_data(cfg.data_path,cfg,usage=\"train\")\r\n",
    "de_test = read_data(cfg.test_path,cfg,usage=\"test\")\r\n",
    "print('训练数据集数量：',de_train.get_dataset_size()*cfg.batch_size)#get_dataset_size()获取批处理的大小。\r\n",
    "print('测试数据集数量：',de_test.get_dataset_size())\r\n",
    "\r\n",
    "\r\n",
    "de_dataset = de_train\r\n",
    "data_next = de_dataset.create_dict_iterator(output_numpy=True).__next__()\r\n",
    "print('通道数/图像长/宽：', data_next['image'][0,...].shape)\r\n",
    "print('一张图像的标签样式：', data_next['label'][0])  # 一共5类，用0-4的数字表达类别。\r\n",
    "\r\n",
    "plt.figure()\r\n",
    "plt.imshow(data_next['image'][0,0,...])\r\n",
    "plt.colorbar()\r\n",
    "plt.grid(False)\r\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/e8dbcbfca8e44b81b9d1e5b08f9bfa2145b64ecb8732467c97eed8775f221590)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 定义模型和学习率函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"ResNet.\"\"\"\r\n",
    "def _weight_variable(shape, factor=0.01):\r\n",
    "    init_value = np.random.randn(*shape).astype(np.float32) * factor\r\n",
    "    return Tensor(init_value)\r\n",
    "\r\n",
    "\r\n",
    "def _conv3x3(in_channel, out_channel, stride=1):\r\n",
    "    weight_shape = (out_channel, in_channel, 3, 3)\r\n",
    "    weight = _weight_variable(weight_shape)\r\n",
    "    return nn.Conv2d(in_channel, out_channel,\r\n",
    "                     kernel_size=3, stride=stride, padding=0, pad_mode='same', weight_init=weight)\r\n",
    "\r\n",
    "\r\n",
    "def _conv1x1(in_channel, out_channel, stride=1):\r\n",
    "    weight_shape = (out_channel, in_channel, 1, 1)\r\n",
    "    weight = _weight_variable(weight_shape)\r\n",
    "    return nn.Conv2d(in_channel, out_channel,\r\n",
    "                     kernel_size=1, stride=stride, padding=0, pad_mode='same', weight_init=weight)\r\n",
    "\r\n",
    "\r\n",
    "def _conv7x7(in_channel, out_channel, stride=1):\r\n",
    "    weight_shape = (out_channel, in_channel, 7, 7)\r\n",
    "    weight = _weight_variable(weight_shape)\r\n",
    "    return nn.Conv2d(in_channel, out_channel,\r\n",
    "                     kernel_size=7, stride=stride, padding=0, pad_mode='same', weight_init=weight)\r\n",
    "\r\n",
    "\r\n",
    "def _bn(channel):\r\n",
    "    return nn.BatchNorm2d(channel, eps=1e-4, momentum=0.9,\r\n",
    "                          gamma_init=1, beta_init=0, moving_mean_init=0, moving_var_init=1)\r\n",
    "\r\n",
    "\r\n",
    "def _bn_last(channel):\r\n",
    "    return nn.BatchNorm2d(channel, eps=1e-4, momentum=0.9,\r\n",
    "                          gamma_init=0, beta_init=0, moving_mean_init=0, moving_var_init=1)\r\n",
    "\r\n",
    "\r\n",
    "def _fc(in_channel, out_channel):\r\n",
    "    weight_shape = (out_channel, in_channel)\r\n",
    "    weight = _weight_variable(weight_shape)\r\n",
    "    return nn.Dense(in_channel, out_channel, has_bias=True, weight_init=weight, bias_init=0)\r\n",
    "\r\n",
    "\r\n",
    "class ResidualBlock(nn.Cell):\r\n",
    "    \"\"\"\r\n",
    "    ResNet V1 residual block definition.\r\n",
    "\r\n",
    "    Args:\r\n",
    "        in_channel (int): Input channel.\r\n",
    "        out_channel (int): Output channel.\r\n",
    "        stride (int): Stride size for the first convolutional layer. Default: 1.\r\n",
    "\r\n",
    "    Returns:\r\n",
    "        Tensor, output tensor.\r\n",
    "\r\n",
    "    Examples:\r\n",
    "        >>> ResidualBlock(3, 256, stride=2)\r\n",
    "    \"\"\"\r\n",
    "    expansion = 4\r\n",
    "\r\n",
    "    def __init__(self,\r\n",
    "                 in_channel,\r\n",
    "                 out_channel,\r\n",
    "                 stride=1):\r\n",
    "        super(ResidualBlock, self).__init__()\r\n",
    "\r\n",
    "        channel = out_channel // self.expansion\r\n",
    "        self.conv1 = _conv1x1(in_channel, channel, stride=1)\r\n",
    "        self.bn1 = _bn(channel)\r\n",
    "\r\n",
    "        self.conv2 = _conv3x3(channel, channel, stride=stride)\r\n",
    "        self.bn2 = _bn(channel)\r\n",
    "\r\n",
    "        self.conv3 = _conv1x1(channel, out_channel, stride=1)\r\n",
    "        self.bn3 = _bn_last(out_channel)\r\n",
    "\r\n",
    "        self.relu = nn.ReLU()\r\n",
    "\r\n",
    "        self.down_sample = False\r\n",
    "\r\n",
    "        if stride != 1 or in_channel != out_channel:\r\n",
    "            self.down_sample = True\r\n",
    "        self.down_sample_layer = None\r\n",
    "\r\n",
    "        if self.down_sample:\r\n",
    "            self.down_sample_layer = nn.SequentialCell([_conv1x1(in_channel, out_channel, stride),\r\n",
    "                                                        _bn(out_channel)])\r\n",
    "        self.add = ops.Add()\r\n",
    "\r\n",
    "    def construct(self, x): # pylint: disable=missing-docstring\r\n",
    "        identity = x\r\n",
    "\r\n",
    "        out = self.conv1(x)\r\n",
    "        out = self.bn1(out)\r\n",
    "        out = self.relu(out)\r\n",
    "\r\n",
    "        out = self.conv2(out)\r\n",
    "        out = self.bn2(out)\r\n",
    "        out = self.relu(out)\r\n",
    "\r\n",
    "        out = self.conv3(out)\r\n",
    "        out = self.bn3(out)\r\n",
    "\r\n",
    "        if self.down_sample:\r\n",
    "            identity = self.down_sample_layer(identity)\r\n",
    "\r\n",
    "        out = self.add(out, identity)\r\n",
    "        out = self.relu(out)\r\n",
    "\r\n",
    "        return out\r\n",
    "\r\n",
    "\r\n",
    "class ResNet(nn.Cell):\r\n",
    "    \"\"\"\r\n",
    "    ResNet architecture.\r\n",
    "\r\n",
    "    Args:\r\n",
    "        block (Cell): Block for network.\r\n",
    "        layer_nums (list): Numbers of block in different layers.\r\n",
    "        in_channels (list): Input channel in each layer.\r\n",
    "        out_channels (list): Output channel in each layer.\r\n",
    "        strides (list):  Stride size in each layer.\r\n",
    "        num_classes (int): The number of classes that the training images are belonging to.\r\n",
    "    Returns:\r\n",
    "        Tensor, output tensor.\r\n",
    "\r\n",
    "    Examples:\r\n",
    "        >>> ResNet(ResidualBlock,\r\n",
    "        >>>        [3, 4, 6, 3],\r\n",
    "        >>>        [64, 256, 512, 1024],\r\n",
    "        >>>        [256, 512, 1024, 2048],\r\n",
    "        >>>        [1, 2, 2, 2],\r\n",
    "        >>>        10)\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    def __init__(self,\r\n",
    "                 block,\r\n",
    "                 layer_nums,\r\n",
    "                 in_channels,\r\n",
    "                 out_channels,\r\n",
    "                 strides,\r\n",
    "                 num_classes):\r\n",
    "        super(ResNet, self).__init__()\r\n",
    "\r\n",
    "        if not len(layer_nums) == len(in_channels) == len(out_channels) == 4:\r\n",
    "            raise ValueError(\"the length of layer_num, in_channels, out_channels list must be 4!\")\r\n",
    "\r\n",
    "        self.conv1 = _conv7x7(3, 64, stride=2)\r\n",
    "        self.bn1 = _bn(64)\r\n",
    "        self.relu = ops.ReLU()\r\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, pad_mode=\"same\")\r\n",
    "\r\n",
    "        self.layer1 = self._make_layer(block,\r\n",
    "                                       layer_nums[0],\r\n",
    "                                       in_channel=in_channels[0],\r\n",
    "                                       out_channel=out_channels[0],\r\n",
    "                                       stride=strides[0])\r\n",
    "        self.layer2 = self._make_layer(block,\r\n",
    "                                       layer_nums[1],\r\n",
    "                                       in_channel=in_channels[1],\r\n",
    "                                       out_channel=out_channels[1],\r\n",
    "                                       stride=strides[1])\r\n",
    "        self.layer3 = self._make_layer(block,\r\n",
    "                                       layer_nums[2],\r\n",
    "                                       in_channel=in_channels[2],\r\n",
    "                                       out_channel=out_channels[2],\r\n",
    "                                       stride=strides[2])\r\n",
    "        self.layer4 = self._make_layer(block,\r\n",
    "                                       layer_nums[3],\r\n",
    "                                       in_channel=in_channels[3],\r\n",
    "                                       out_channel=out_channels[3],\r\n",
    "                                       stride=strides[3])\r\n",
    "\r\n",
    "        self.mean = ops.ReduceMean(keep_dims=True)\r\n",
    "        self.flatten = nn.Flatten()\r\n",
    "        self.end_point = _fc(out_channels[3], num_classes)\r\n",
    "\r\n",
    "    def _make_layer(self, block, layer_num, in_channel, out_channel, stride):\r\n",
    "        \"\"\"\r\n",
    "        Make stage network of ResNet.\r\n",
    "\r\n",
    "        Args:\r\n",
    "            block (Cell): Resnet block.\r\n",
    "            layer_num (int): Layer number.\r\n",
    "            in_channel (int): Input channel.\r\n",
    "            out_channel (int): Output channel.\r\n",
    "            stride (int): Stride size for the first convolutional layer.\r\n",
    "\r\n",
    "        Returns:\r\n",
    "            SequentialCell, the output layer.\r\n",
    "\r\n",
    "        Examples:\r\n",
    "            >>> _make_layer(ResidualBlock, 3, 128, 256, 2)\r\n",
    "        \"\"\"\r\n",
    "        layers = []\r\n",
    "\r\n",
    "        resnet_block = block(in_channel, out_channel, stride=stride)\r\n",
    "        layers.append(resnet_block)\r\n",
    "\r\n",
    "        for _ in range(1, layer_num):\r\n",
    "            resnet_block = block(out_channel, out_channel, stride=1)\r\n",
    "            layers.append(resnet_block)\r\n",
    "\r\n",
    "        return nn.SequentialCell(layers)\r\n",
    "\r\n",
    "    def construct(self, x): # pylint: disable=missing-docstring\r\n",
    "        x = self.conv1(x)\r\n",
    "        x = self.bn1(x)\r\n",
    "        x = self.relu(x)\r\n",
    "        c1 = self.maxpool(x)\r\n",
    "\r\n",
    "        c2 = self.layer1(c1)\r\n",
    "        c3 = self.layer2(c2)\r\n",
    "        c4 = self.layer3(c3)\r\n",
    "        c5 = self.layer4(c4)\r\n",
    "\r\n",
    "        out = self.mean(c5, (2, 3))\r\n",
    "        out = self.flatten(out)\r\n",
    "        out = self.end_point(out)\r\n",
    "\r\n",
    "        return out\r\n",
    "\r\n",
    "\r\n",
    "def resnet50(class_num=10):\r\n",
    "    \"\"\"\r\n",
    "    Get ResNet50 neural network.\r\n",
    "\r\n",
    "    Args:\r\n",
    "        class_num (int): Class number.\r\n",
    "\r\n",
    "    Returns:\r\n",
    "        Cell, cell instance of ResNet50 neural network.\r\n",
    "\r\n",
    "    Examples:\r\n",
    "        >>> net = resnet50(10)\r\n",
    "    \"\"\"\r\n",
    "    return ResNet(ResidualBlock,\r\n",
    "                  [3, 4, 6, 3],\r\n",
    "                  [64, 256, 512, 1024],\r\n",
    "                  [256, 512, 1024, 2048],\r\n",
    "                  [1, 2, 2, 2],\r\n",
    "                  class_num)\r\n",
    "\r\n",
    "\r\n",
    "def resnet101(class_num=1001):\r\n",
    "    \"\"\"\r\n",
    "    Get ResNet101 neural network.\r\n",
    "\r\n",
    "    Args:\r\n",
    "        class_num (int): Class number.\r\n",
    "\r\n",
    "    Returns:\r\n",
    "        Cell, cell instance of ResNet101 neural network.\r\n",
    "\r\n",
    "    Examples:\r\n",
    "        >>> net = resnet101(1001)\r\n",
    "    \"\"\"\r\n",
    "    return ResNet(ResidualBlock,\r\n",
    "                  [3, 4, 23, 3],\r\n",
    "                  [64, 256, 512, 1024],\r\n",
    "                  [256, 512, 1024, 2048],\r\n",
    "                  [1, 2, 2, 2],\r\n",
    "                  class_num)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_lr(global_step,\r\n",
    "           total_epochs,\r\n",
    "           steps_per_epoch,\r\n",
    "           lr_init=0.01,\r\n",
    "           lr_max=0.1,\r\n",
    "           warmup_epochs=5):\r\n",
    "    \"\"\"\r\n",
    "    Generate learning rate array.\r\n",
    "\r\n",
    "    Args:\r\n",
    "        global_step (int): Initial step of training.\r\n",
    "        total_epochs (int): Total epoch of training.\r\n",
    "        steps_per_epoch (float): Steps of one epoch.\r\n",
    "        lr_init (float): Initial learning rate. Default: 0.01.\r\n",
    "        lr_max (float): Maximum learning rate. Default: 0.1.\r\n",
    "        warmup_epochs (int): The number of warming up epochs. Default: 5.\r\n",
    "\r\n",
    "    Returns:\r\n",
    "        np.array, learning rate array.\r\n",
    "    \"\"\"\r\n",
    "    lr_each_step = []\r\n",
    "    total_steps = steps_per_epoch * total_epochs\r\n",
    "    warmup_steps = steps_per_epoch * warmup_epochs\r\n",
    "    if warmup_steps != 0:\r\n",
    "        inc_each_step = (float(lr_max) - float(lr_init)) / float(warmup_steps)\r\n",
    "    else:\r\n",
    "        inc_each_step = 0\r\n",
    "    for i in range(int(total_steps)):\r\n",
    "        if i < warmup_steps:\r\n",
    "            lr = float(lr_init) + inc_each_step * float(i)\r\n",
    "        else:\r\n",
    "            base = ( 1.0 - (float(i) - float(warmup_steps)) / (float(total_steps) - float(warmup_steps)) )\r\n",
    "            lr = float(lr_max) * base * base\r\n",
    "            if lr < 0.0:\r\n",
    "                lr = 0.0\r\n",
    "        lr_each_step.append(lr)\r\n",
    "\r\n",
    "    current_step = global_step\r\n",
    "    lr_each_step = np.array(lr_each_step).astype(np.float32)\r\n",
    "    learning_rate = lr_each_step[current_step:]\r\n",
    "\r\n",
    "    return learning_rate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net=resnet50(class_num=cfg.num_class)\r\n",
    "#计算softmax交叉熵。\r\n",
    "loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction=\"mean\")\r\n",
    "#设置优化器\r\n",
    "train_step_size = de_train.get_dataset_size()\r\n",
    "#lr = Tensor(get_lr(global_step=0, total_epochs=cfg.epoch_size, steps_per_epoch=train_step_size))\r\n",
    "lr = 0.001\r\n",
    "opt = Momentum(net.trainable_params(), lr, momentum=0.9, weight_decay=1e-4, loss_scale=cfg.loss_scale_num)\r\n",
    "#opt = Momentum(filter(lambda x: x.requires_grad, net.get_parameters()), 0.002,\r\n",
    "#                       0.9, 0.00004, loss_scale=1024.0)\r\n",
    "loss_scale = FixedLossScaleManager(cfg.loss_scale_num, False)\r\n",
    "\r\n",
    "model = Model(net, loss_fn=loss, optimizer=opt, loss_scale_manager=loss_scale, metrics={'acc'})\r\n",
    "loss_cb = LossMonitor(per_print_times=train_step_size)\r\n",
    "ckpt_config = CheckpointConfig(save_checkpoint_steps=cfg.save_checkpoint_steps, keep_checkpoint_max=1)\r\n",
    "ckpoint_cb = ModelCheckpoint(prefix=cfg.prefix, directory=cfg.directory, config=ckpt_config)\r\n",
    "\r\n",
    "print(\"============== Starting Training ==============\")\r\n",
    "model.train(cfg.epoch_size, de_train, callbacks=[loss_cb,ckpoint_cb], dataset_sink_mode=True)\r\n",
    "# 使用测试集评估模型，打印总体准确率\r\n",
    "metric = model.eval(de_test)\r\n",
    "print(metric) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/bf3cdb07354041038a91ef228b5dabc82a1436b7357f4a17b3cac835ed5487de)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "但是，训练到结尾部分会报错，RuntimeError: mindspore/ccsrc/runtime/graph_scheduler/graph_scheduler.cc:619 Run] Launch graph failed, graph id: 1，找了挺多资料都没办法解决"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
